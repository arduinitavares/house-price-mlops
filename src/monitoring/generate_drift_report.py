"""
Gera relatÃ³rio de drift de dados comparando referÃªncia e produÃ§Ã£o
usando Evidently AI e salva como JSON.
"""

import json
import os

import pandas as pd
from evidently import Report
from evidently.presets import DataDriftPreset


def load_data(reference_path: str, production_path: str) \
        -> tuple[pd.DataFrame, pd.DataFrame]:
    """Carrega e imprime informaÃ§Ãµes bÃ¡sicas dos datasets."""
    print(f"ðŸ“¥ Lendo dados de referÃªncia de: {reference_path}")
    ref_df = pd.read_csv(reference_path)
    print(f"   â†’ shape {ref_df.shape}")

    print(f"ðŸ“¥ Lendo dados de produÃ§Ã£o de: {production_path}")
    prod_df = pd.read_csv(production_path)
    print(f"   â†’ shape {prod_df.shape}")

    return ref_df, prod_df


def generate_drift_report(
    reference_df: pd.DataFrame,
    production_df: pd.DataFrame,
    output_path: str,
) -> None:
    """Gera e salva um relatÃ³rio JSON de drift de dados."""
    print("âš™ï¸ Gerando relatÃ³rio de Data Drift...")

    # ConfiguraÃ§Ã£o para suprimir warnings especÃ­ficos
    import warnings

    from sklearn.exceptions import UndefinedMetricWarning
    warnings.filterwarnings("ignore", category=UndefinedMetricWarning)
    warnings.filterwarnings("ignore", category=RuntimeWarning,
                            message="divide by zero encountered in divide")

    # Cria e executa o relatÃ³rio
    report = Report(metrics=[DataDriftPreset()])
    report.run(reference_data=reference_df, current_data=production_df)

    # Cria o diretÃ³rio de saÃ­da se nÃ£o existir
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # Cria um dicionÃ¡rio com informaÃ§Ãµes bÃ¡sicas sobre o drift
    result_dict = {
        "timestamp": str(pd.Timestamp.now()),
        "reference_shape": reference_df.shape,
        "production_shape": production_df.shape,
        "metrics": []
    }

    # Adiciona metadata se disponÃ­vel
    if hasattr(report, "metadata") and report.metadata:
        result_dict["metadata"] = report.metadata

    # Calculamos manualmente o drift entre os datasets
    drift_results = {
        "drift_share_config": 0.5,  # Valor default de configuraÃ§Ã£o
        "features_drifted": 0,
        "features_analyzed": 0,
        "drift_share_detected": 0.0,
        "drifted_features": []
    }

    # Vamos analisar coluna por coluna
    common_columns = set(reference_df.columns) & set(production_df.columns)
    features_analyzed = 0
    features_drifted = 0

    from scipy import stats

    for col in common_columns:
        # Ignoramos colunas que sejam completamente nulas
        if reference_df[col].isnull().all() or production_df[col].isnull().all():
            continue

        features_analyzed += 1

        # Para colunas numÃ©ricas, usamos teste KS
        if pd.api.types.is_numeric_dtype(reference_df[col]):
            ref_data = reference_df[col].dropna()
            prod_data = production_df[col].dropna()

            if len(ref_data) > 0 and len(prod_data) > 0:
                # Teste de Kolmogorov-Smirnov
                ks_stat, p_value = stats.ks_2samp(ref_data, prod_data)

                # Se p-value < 0.05, consideramos que houve drift
                is_drifted = p_value < 0.05

                if is_drifted:
                    features_drifted += 1
                    drift_results["drifted_features"].append({
                        "name": col,
                        "p_value": float(p_value),
                        "stat": float(ks_stat)
                    })

    # Calculamos a proporÃ§Ã£o de features que sofreram drift
    if features_analyzed > 0:
        drift_results["features_analyzed"] = features_analyzed
        drift_results["features_drifted"] = features_drifted
        drift_results["drift_share_detected"] = features_drifted / \
            features_analyzed

    # Adicionamos ao relatÃ³rio
    metric_info = {
        "type": "DataDriftPreset",
        "config": {
            "drift_share": 0.5,  # Threshold configurado no preset
            "threshold": None,
            "columns": None
        },
        "results": drift_results
    }

    result_dict["metrics"].append(metric_info)

    # Salva o relatÃ³rio no formato JSON
    with open(output_path, "w") as f:
        json.dump(result_dict, f, indent=2)
    print(f"âœ… RelatÃ³rio JSON salvo em: {output_path}")
    print(
        f"ðŸ“Š Drift detectado: {drift_results['drift_share_detected']:.4f} ({features_drifted}/{features_analyzed} features)")


if __name__ == "__main__":
    # Ajuste estas paths conforme a sua estrutura:
    reference_file = "data/processed/train_data.csv"
    production_file = "data/processed/test_data.csv"
    report_output = "reports/data_drift_report.json"

    ref_data, prod_data = load_data(reference_file, production_file)
    generate_drift_report(ref_data, prod_data, report_output)
